{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from mltu.tensorflow.model_utils import residual_block\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from mltu.preprocessors import ImageReader\n",
    "from configs import ModelConfigs\n",
    "from mltu.tensorflow.callbacks import TrainLogger\n",
    "from mltu.tensorflow.metrics import CWERMetric\n",
    "from tensorflow.keras.models import load_model\n",
    "from mltu.annotations.images import CVImage\n",
    "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding\n",
    "from mltu.tensorflow.losses import CTCloss\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim, activation=\"leaky_relu\", dropout=0.2):\n",
    "    inputs = layers.Input(shape=input_dim, name='input')\n",
    "    input = layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    x1 = residual_block(input, 16, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "    x2 = residual_block(x1, 16, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x3 = residual_block(x2, 16, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "    x4 = residual_block(x3, 32, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x5 = residual_block(x4, 32, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "    x6 = residual_block(x5, 64, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "    x7 = residual_block(x6, 64, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    squeezed = layers.Reshape((x7.shape[-3] * x7.shape[-2], x7.shape[-1]))(x7)\n",
    "    bi_LSTM = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(squeezed)\n",
    "    output = layers.Dense(output_dim + 1, activation=\"softmax\", name=\"output\")(bi_LSTM)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ModelConfigs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = \"./dataset/IDCAR2015_Dataset/train/training_images/\"\n",
    "train_annotations_path = \"./dataset/IDCAR2015_Dataset/train/training_localization_transcription\"\n",
    "val_images_path = \"./dataset/IDCAR2015_Dataset/val/val_images/\"\n",
    "val_annotations_path = \"./dataset/IDCAR2015_Dataset/val/val_localization_transcription\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotation_file(image_folder, annotations_folder):\n",
    "    dataset, vocab, max_len = [], set(), 0\n",
    "\n",
    "    # Get sorted lists of image and annotation files to ensure they match\n",
    "    image_files = sorted(os.listdir(image_folder))\n",
    "    annotation_files = sorted(os.listdir(annotations_folder))\n",
    "\n",
    "    # Use zip to combine image and annotation files\n",
    "    for image_file, annotation_file in tqdm(zip(image_files, annotation_files)):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        annotation_path = os.path.join(annotations_folder, annotation_file)\n",
    "\n",
    "        # Read the annotation file\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip().split()\n",
    "                \n",
    "                # Assuming the annotation contains the image name and the label\n",
    "                label = line[1] if len(line) > 1 else \"UNKNOWN\"  # Handle missing label\n",
    "\n",
    "                # Append image path and label to the dataset\n",
    "                dataset.append([image_path, label])\n",
    "                vocab.update(list(label))\n",
    "                max_len = max(max_len, len(label))\n",
    "\n",
    "    return dataset, sorted(vocab), max_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 4800.00it/s]\n",
      "500it [00:00, 4104.47it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_vocab, max_train_len = read_annotation_file(train_images_path, train_annotations_path)\n",
    "val_dataset, val_vocab, max_val_len = read_annotation_file(val_images_path, val_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data provider\n",
    "train_data_provider = DataProvider(\n",
    "    dataset=train_dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        ImageResizer(configs.width, configs.height),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab))\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Create validation data provider\n",
    "val_data_provider = DataProvider(\n",
    "    dataset=val_dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        ImageResizer(configs.width, configs.height),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab))\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\1288843.TRANSIT.000\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1288843.TRANSIT.000\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = create_model(input_dim=(configs.height, configs.width, 3), output_dim=len(configs.vocab))\n",
    "padding_token = len(configs.vocab)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate), loss=CTCloss(), run_eagerly=False)\n",
    "#model.summary()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "earlystopper = EarlyStopping(monitor=\"val_CER\", patience=10, mode='min', verbose=1)\n",
    "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.keras\", monitor=\"val_CER\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "trainLogger = TrainLogger(configs.model_path)\n",
    "tb_callback = TensorBoard(f\"{configs.model_path}/logs\", update_freq=1)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor=\"val_CER\", factor=0.9, min_delta=1e-10, patience=5, verbose=1, mode=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 9s/step - loss: 777.5939 - val_loss: 862.8233 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1288843.TRANSIT.000\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_CER` which is not available. Available metrics are: loss,val_loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "c:\\Users\\1288843.TRANSIT.000\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_CER available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n",
      "c:\\Users\\1288843.TRANSIT.000\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:96: UserWarning: Learning rate reduction is conditioned on metric `val_CER` which is not available. Available metrics are: loss,val_loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 628.6485 - val_loss: 747.6307 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 8s/step - loss: 484.5318 - val_loss: 601.3226 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - loss: 354.3723 - val_loss: 454.9121 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 7s/step - loss: 248.7078 - val_loss: 310.7771 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 171.4536 - val_loss: 183.0749 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 8s/step - loss: 121.6573 - val_loss: 108.1963 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 8s/step - loss: 91.4814 - val_loss: 76.0702 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 8s/step - loss: 73.7003 - val_loss: 61.4241 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 10s/step - loss: 63.2931 - val_loss: 54.3486 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 8s/step - loss: 57.6257 - val_loss: 50.5018 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 8s/step - loss: 53.2743 - val_loss: 48.2345 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 8s/step - loss: 48.7364 - val_loss: 46.6697 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 8s/step - loss: 46.7525 - val_loss: 45.3950 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 10s/step - loss: 46.0202 - val_loss: 44.1900 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 14s/step - loss: 42.9232 - val_loss: 42.9458 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 14s/step - loss: 41.4023 - val_loss: 41.7486 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 13s/step - loss: 39.8883 - val_loss: 40.6491 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 7s/step - loss: 38.0767 - val_loss: 39.6155 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 38.2219 - val_loss: 38.6383 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - loss: 35.4931 - val_loss: 37.7138 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 7s/step - loss: 34.9525 - val_loss: 36.7906 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 8s/step - loss: 34.0772 - val_loss: 35.8780 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 8s/step - loss: 32.1396 - val_loss: 34.9523 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8s/step - loss: 32.5556 - val_loss: 33.9916 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 31.0556 - val_loss: 33.0836 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7s/step - loss: 29.9118 - val_loss: 32.2216 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 28.9035 - val_loss: 31.3737 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 27.2871 - val_loss: 30.5551 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 27.4473 - val_loss: 29.7416 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 8s/step - loss: 27.0392 - val_loss: 28.9022 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 7s/step - loss: 24.5465 - val_loss: 28.0330 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 24.2934 - val_loss: 27.1999 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 24.8131 - val_loss: 26.4281 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 23.1252 - val_loss: 25.6900 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 22.5510 - val_loss: 25.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 20.9496 - val_loss: 24.2978 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 21.1950 - val_loss: 23.6092 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 7s/step - loss: 21.1413 - val_loss: 22.9471 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 18.6023 - val_loss: 22.3476 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 19.9128 - val_loss: 21.7158 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 19.1307 - val_loss: 21.1358 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 18.9401 - val_loss: 20.6019 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 18.8077 - val_loss: 20.0951 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 16.6393 - val_loss: 19.5971 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 16.9975 - val_loss: 19.1192 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 16.2617 - val_loss: 18.6880 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 18.3609 - val_loss: 18.3010 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 16.9424 - val_loss: 17.8822 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 15.3805 - val_loss: 17.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 14.1818 - val_loss: 17.1282 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 14.9051 - val_loss: 16.8171 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 14.4211 - val_loss: 16.4685 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 13.7055 - val_loss: 16.0965 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 15.6814 - val_loss: 15.8275 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 8s/step - loss: 13.4234 - val_loss: 15.5320 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 12.5299 - val_loss: 15.2192 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 13.5903 - val_loss: 14.9501 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 13.8098 - val_loss: 14.7109 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 13.8163 - val_loss: 14.4499 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 12.2305 - val_loss: 14.2271 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 12.2149 - val_loss: 14.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 11.8299 - val_loss: 13.7928 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 12.6764 - val_loss: 13.5974 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 13.0467 - val_loss: 13.3875 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 10.6761 - val_loss: 13.2403 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 10.9653 - val_loss: 13.0628 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 10.2067 - val_loss: 12.9085 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 11.3512 - val_loss: 12.7561 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 8s/step - loss: 11.1049 - val_loss: 12.6037 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 7s/step - loss: 11.0398 - val_loss: 12.4768 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 7s/step - loss: 10.8498 - val_loss: 12.3437 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 7s/step - loss: 10.3360 - val_loss: 12.2423 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 9.9131 - val_loss: 12.1174 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 9.5486 - val_loss: 12.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 8s/step - loss: 9.5859 - val_loss: 11.8855 - learning_rate: 1.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - loss: 9.1385 - val_loss: 11.7986 - learning_rate: 1.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 8s/step - loss: 8.8997 - val_loss: 11.7050 - learning_rate: 1.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 7s/step - loss: 9.8151 - val_loss: 11.5835 - learning_rate: 1.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 9.3832 - val_loss: 11.5006 - learning_rate: 1.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 9.5525 - val_loss: 11.4097 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 8.1561 - val_loss: 11.3397 - learning_rate: 1.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 8.8188 - val_loss: 11.2429 - learning_rate: 1.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 8s/step - loss: 9.0275 - val_loss: 11.1690 - learning_rate: 1.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7s/step - loss: 9.1005 - val_loss: 11.0761 - learning_rate: 1.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 8.3195 - val_loss: 11.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 7.0366 - val_loss: 10.9306 - learning_rate: 1.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 9.0382 - val_loss: 10.8610 - learning_rate: 1.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 8.5579 - val_loss: 10.7985 - learning_rate: 1.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 7.5813 - val_loss: 10.7290 - learning_rate: 1.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 8.4406 - val_loss: 10.6762 - learning_rate: 1.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 8s/step - loss: 7.8044 - val_loss: 10.5835 - learning_rate: 1.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 7.8776 - val_loss: 10.5063 - learning_rate: 1.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - loss: 7.0810 - val_loss: 10.4379 - learning_rate: 1.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 9.0708 - val_loss: 10.3758 - learning_rate: 1.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - loss: 7.7605 - val_loss: 10.3168 - learning_rate: 1.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 7s/step - loss: 8.5785 - val_loss: 10.2574 - learning_rate: 1.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 7s/step - loss: 7.0692 - val_loss: 10.1948 - learning_rate: 1.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 7s/step - loss: 9.0223 - val_loss: 10.1482 - learning_rate: 1.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 7s/step - loss: 7.6364 - val_loss: 10.0916 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data_provider,\n",
    "    validation_data=val_data_provider,\n",
    "    epochs=configs.train_epochs,\n",
    "    callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('textocr_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss(y_true, y_red):\n",
    "    return K.ctc_batch_cost(y_true, y_red, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('textocr_model.h5', custom_objects={'CTCloss': ctc_loss})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
